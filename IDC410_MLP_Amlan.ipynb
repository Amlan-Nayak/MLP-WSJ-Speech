{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3eVsI8QFUP5v"
      },
      "outputs": [],
      "source": [
        "\n",
        "#loading the files as given in assignment\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "class WSJ():\n",
        "    \"\"\" Load the WSJ speech dataset\n",
        "        \n",
        "        Ensure WSJ_PATH is path to directory containing \n",
        "        all data files (.npy) provided on Kaggle.\n",
        "        \n",
        "        Example usage:\n",
        "            loader = WSJ()\n",
        "            trainX, trainY = loader.train\n",
        "            assert(trainX.shape[0] == 24590)\n",
        "            \n",
        "    \"\"\"\n",
        "  \n",
        "    def _init_(self):\n",
        "        self.dev_set = None\n",
        "        self.train_set = None\n",
        "        self.test_set = None\n",
        "  \n",
        "    @property\n",
        "    def dev(self):\n",
        "        if self.dev_set is None:\n",
        "            self.dev_set = load_raw(os.environ['WSJ_PATH'], 'dev')\n",
        "        return self.dev_set\n",
        "\n",
        "    @property\n",
        "    def train(self):\n",
        "        if self.train_set is None:\n",
        "            self.train_set = load_raw(os.environ['WSJ_PATH'], 'train')\n",
        "        return self.train_set\n",
        "  \n",
        "    @property\n",
        "    def test(self):\n",
        "        if self.test_set is None:\n",
        "            self.test_set = (np.load(os.path.join(os.environ['WSJ_PATH'], 'test.npy'), encoding='bytes'), None)\n",
        "        return self.test_set\n",
        "    \n",
        "def load_raw(path, name):\n",
        "    return (\n",
        "        np.load(os.path.join(path, '{}.npy'.format(name)), encoding='bytes',allow_pickle=True), \n",
        "        np.load(os.path.join(path, '{}_labels.npy'.format(name)), encoding='bytes',allow_pickle=True)\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "smDneoRqVTvZ",
        "outputId": "e89a03da-978f-410a-cefa-1351b380a29f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t5y9kB-4UP5x"
      },
      "outputs": [],
      "source": [
        "#loading the X and Y data\n",
        "file='/content/drive/MyDrive/NN/'\n",
        "files = load_raw(file,'dev')\n",
        "X = files[0]\n",
        "Y = files[1]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fgHu7w-wUP5z",
        "outputId": "0860517f-74d9-414f-e20f-9b8663d4d030"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((388, 40), (388,))"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "X[0].shape,Y[0].shape"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Stacking the data as it is an array of arrays\n",
        "X=np.vstack(X)\n",
        "Y = np.hstack(Y)"
      ],
      "metadata": {
        "id": "tGpPRlQmePps"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X.shape,Y.shape"
      ],
      "metadata": {
        "id": "mDaHSpIqdUXa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6cf7c8f5-e0f0-4643-a496-ebd9bf37ea63"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((669294, 40), (669294,))"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Flatten\n",
        "from keras.utils import np_utils\n",
        "from keras.wrappers.scikit_learn import KerasClassifier\n",
        "\n",
        "#dividing the data into train,test and validation for hyperparameter tuning\n",
        "\n",
        "X_train,X_test,Y_train,Y_test = train_test_split(X,Y.reshape(-1,1),test_size=0.3,random_state=42)\n",
        "\n",
        "X_val = X_train[-10000:]\n",
        "X_train = X_train[:-10000]\n",
        "Y_val = Y_train[-10000:]\n",
        "Y_train = Y_train[:-10000]"
      ],
      "metadata": {
        "id": "kRFyMhMmkEc3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#using garbage collector to delete unneeded data and release memory\n",
        "import gc\n",
        "del X\n",
        "del Y\n",
        "gc.collect()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LkQ6seJDIwPF",
        "outputId": "0e67c390-dc3b-439d-ee23-063bf7448f7b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "140"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "import keras_tuner as kt\n",
        "from keras_tuner.engine.tuner_utils import TunerStats\n",
        "\n",
        "#Converting the Y data into 138 categories\n",
        "\n",
        "num_classes = 138\n",
        "Y_train = keras.utils.to_categorical(Y_train, num_classes)\n",
        "Y_val = keras.utils.to_categorical(Y_val, num_classes)\n",
        "Y_test = keras.utils.to_categorical(Y_test, num_classes)"
      ],
      "metadata": {
        "id": "00Zz9Gbrz0DG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Hyper Parameter Tuning to Find the accurate most single hidden layer MLP"
      ],
      "metadata": {
        "id": "g1_sGdnII7-P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#I first tried maximizing accurcy using a single hidden layer. Here we tune th hyperparameters.\n",
        "#Single Layer\n",
        "class MyHyperModel(kt.HyperModel):\n",
        "    def build(self, hp):\n",
        "        model = keras.Sequential()\n",
        "        model.add(layers.Flatten())\n",
        "        model.add(layers.Dense(units=hp.Int('units', 32, 512, step=32), activation=hp.Choice('activation', ['relu', 'tanh'])))    \n",
        "        model.add(layers.Dense(138, activation=\"softmax\"))\n",
        "        learning_rate = hp.Choice(\"lr\", [0.0001,0.001,0.01,0.1])\n",
        "        model.compile(\n",
        "            keras.optimizers.Adam(learning_rate=learning_rate), loss=\"categorical_crossentropy\", metrics=[\"accuracy\"],\n",
        "        )\n",
        "        return model\n",
        "\n",
        "    def fit(self, hp, model, *args, **kwargs):\n",
        "        return model.fit(\n",
        "            *args,\n",
        "            batch_size=hp.Choice(\"batch_size\", [256]),\n",
        "            **kwargs,\n",
        "        )\n",
        "\n",
        "Tuner_single = kt.RandomSearch(\n",
        "    MyHyperModel(),\n",
        "    objective=\"val_accuracy\",\n",
        "    max_trials=5,\n",
        "    overwrite=True,\n",
        "    directory=\"my_dir\",\n",
        "    project_name=\"tune_hypermodel_single\",\n",
        ")"
      ],
      "metadata": {
        "id": "DiSEVmtOHxSc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Single Layer\n",
        "Tuner_single.search_space_summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y0O67gIPI7O6",
        "outputId": "6f2da2dc-b446-4f8d-efef-132e19a8d14d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Search space summary\n",
            "Default search space size: 3\n",
            "units (Int)\n",
            "{'default': None, 'conditions': [], 'min_value': 32, 'max_value': 512, 'step': 32, 'sampling': None}\n",
            "activation (Choice)\n",
            "{'default': 'relu', 'conditions': [], 'values': ['relu', 'tanh'], 'ordered': False}\n",
            "lr (Choice)\n",
            "{'default': 0.0001, 'conditions': [], 'values': [0.0001, 0.001, 0.01, 0.1], 'ordered': True}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Tuner_single.search(X_train, Y_train, epochs=5, validation_data=(X_val, Y_val),callbacks=[tf.keras.callbacks.EarlyStopping('val_loss', patience=3))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L8Bb4f5EJLbN",
        "outputId": "3b410f28-1d4d-4fa1-fd66-b2ea1fc2cd2f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 5 Complete [00h 01m 06s]\n",
            "val_accuracy: 0.25380000472068787\n",
            "\n",
            "Best val_accuracy So Far: 0.25380000472068787\n",
            "Total elapsed time: 00h 05m 29s\n",
            "INFO:tensorflow:Oracle triggered exit\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Max accuracy for single hidden layer with random parameter search is 25.3 percent"
      ],
      "metadata": {
        "id": "NAil9SMfqxEl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Tuner_single.results_summary()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jfIOpCfYRUP5",
        "outputId": "ec1c6bd1-53db-448b-c290-5c3d7828e6fe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Results summary\n",
            "Results in my_dir/tune_hypermodel_single\n",
            "Showing 10 best trials\n",
            "<keras_tuner.engine.objective.Objective object at 0x7f00f3f0fed0>\n",
            "Trial summary\n",
            "Hyperparameters:\n",
            "units: 448\n",
            "activation: tanh\n",
            "lr: 0.0001\n",
            "batch_size: 256\n",
            "Score: 0.25380000472068787\n",
            "Trial summary\n",
            "Hyperparameters:\n",
            "units: 384\n",
            "activation: relu\n",
            "lr: 0.01\n",
            "batch_size: 256\n",
            "Score: 0.20679999887943268\n",
            "Trial summary\n",
            "Hyperparameters:\n",
            "units: 32\n",
            "activation: relu\n",
            "lr: 0.0001\n",
            "batch_size: 256\n",
            "Score: 0.2054000049829483\n",
            "Trial summary\n",
            "Hyperparameters:\n",
            "units: 384\n",
            "activation: tanh\n",
            "lr: 0.1\n",
            "batch_size: 256\n",
            "Score: 0.09529999643564224\n",
            "Trial summary\n",
            "Hyperparameters:\n",
            "units: 128\n",
            "activation: relu\n",
            "lr: 0.1\n",
            "batch_size: 256\n",
            "Score: 0.08009999990463257\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Using the hyperparameters, we build our single hidden layer model \n",
        "model = keras.Sequential()\n",
        "model.add(layers.Flatten())\n",
        "model.add(layers.Dense(units=448, activation='tanh'))    \n",
        "model.add(layers.Dense(138, activation=\"softmax\"))\n",
        "model.compile(keras.optimizers.Adam(learning_rate=0.001), loss=\"categorical_crossentropy\", metrics=[\"accuracy\"],)"
      ],
      "metadata": {
        "id": "ioypOcW_XEdm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Fitting the single hidden layer model to data, stopped midway as it took a long time\n",
        "model.fit(\n",
        "    x=X_train,\n",
        "    y=Y_train,\n",
        "    batch_size=256,\n",
        "    epochs=15,\n",
        "    verbose=\"auto\",\n",
        "    callbacks=None,\n",
        "    validation_split=0.1,\n",
        "    validation_data=None,\n",
        "    shuffle=True,\n",
        "    class_weight=None,\n",
        "    sample_weight=None,\n",
        "    initial_epoch=0,\n",
        "    steps_per_epoch=None,\n",
        "    validation_steps=None,\n",
        "    validation_batch_size=None,\n",
        "    validation_freq=1,\n",
        "    max_queue_size=10,\n",
        "    workers=-1,\n",
        "    use_multiprocessing=True,\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 861
        },
        "id": "nuE7vw-TYPyz",
        "outputId": "2e7a3585-d54d-410e-df6d-b640432a757f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15\n",
            "1612/1612 [==============================] - 13s 8ms/step - loss: 3.5733 - accuracy: 0.1938 - val_loss: 3.5733 - val_accuracy: 0.2013\n",
            "Epoch 2/15\n",
            "1612/1612 [==============================] - 14s 8ms/step - loss: 3.5718 - accuracy: 0.1934 - val_loss: 3.6360 - val_accuracy: 0.2031\n",
            "Epoch 3/15\n",
            "1612/1612 [==============================] - 13s 8ms/step - loss: 3.5689 - accuracy: 0.1944 - val_loss: 3.5597 - val_accuracy: 0.2091\n",
            "Epoch 4/15\n",
            "1612/1612 [==============================] - 13s 8ms/step - loss: 3.5741 - accuracy: 0.1939 - val_loss: 3.5120 - val_accuracy: 0.1926\n",
            "Epoch 5/15\n",
            "1612/1612 [==============================] - 14s 8ms/step - loss: 3.5681 - accuracy: 0.1949 - val_loss: 3.5983 - val_accuracy: 0.1950\n",
            "Epoch 6/15\n",
            "1612/1612 [==============================] - 13s 8ms/step - loss: 3.5705 - accuracy: 0.1953 - val_loss: 3.5990 - val_accuracy: 0.1791\n",
            "Epoch 7/15\n",
            "1612/1612 [==============================] - 13s 8ms/step - loss: 3.5783 - accuracy: 0.1940 - val_loss: 3.6005 - val_accuracy: 0.1902\n",
            "Epoch 8/15\n",
            "1612/1612 [==============================] - 13s 8ms/step - loss: 3.5730 - accuracy: 0.1946 - val_loss: 3.5187 - val_accuracy: 0.1821\n",
            "Epoch 9/15\n",
            "1612/1612 [==============================] - 13s 8ms/step - loss: 3.5692 - accuracy: 0.1958 - val_loss: 3.5232 - val_accuracy: 0.1831\n",
            "Epoch 10/15\n",
            "1612/1612 [==============================] - 14s 9ms/step - loss: 3.5596 - accuracy: 0.1970 - val_loss: 3.6139 - val_accuracy: 0.2030\n",
            "Epoch 11/15\n",
            "1612/1612 [==============================] - 15s 9ms/step - loss: 3.5690 - accuracy: 0.1958 - val_loss: 3.6418 - val_accuracy: 0.1910\n",
            "Epoch 12/15\n",
            "1612/1612 [==============================] - 15s 9ms/step - loss: 3.5572 - accuracy: 0.1961 - val_loss: 3.6460 - val_accuracy: 0.1735\n",
            "Epoch 13/15\n",
            "1612/1612 [==============================] - 15s 9ms/step - loss: 3.5687 - accuracy: 0.1958 - val_loss: 3.6301 - val_accuracy: 0.1978\n",
            "Epoch 14/15\n",
            "1612/1612 [==============================] - 14s 9ms/step - loss: 3.5604 - accuracy: 0.1957 - val_loss: 3.5696 - val_accuracy: 0.2074\n",
            "Epoch 15/15\n",
            "1612/1612 [==============================] - 14s 8ms/step - loss: 3.5630 - accuracy: 0.1967 - val_loss: 3.5939 - val_accuracy: 0.1788\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-47-93adc79c6b93>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m     \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m )\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Trying to use multiple layers to improve accuracy of MLP"
      ],
      "metadata": {
        "id": "lncJhmEwrLeH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We tune our hyper parameters for multiple layers here"
      ],
      "metadata": {
        "id": "es_5vbUyrUxz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MyHyperModel(kt.HyperModel):\n",
        "    def build(self, hp):\n",
        "        model = keras.Sequential()\n",
        "        model.add(layers.Flatten())\n",
        "\n",
        "        for i in range(hp.Int('layers', 1, 5)):\n",
        "           model.add(layers.Dense(units=hp.Int('units_' + str(i), 32, 512, step=32), activation=hp.Choice('act_' + str(i), ['relu', 'tanh'])))\n",
        "           if i < 4 :\n",
        "             model.add(layers.Dropout(rate=0.2))\n",
        "        \n",
        "        model.add(layers.Dense(138, activation=\"softmax\"))\n",
        "        learning_rate = hp.Choice(\"lr\", [0.0001,0.001,0.01,0.1])\n",
        "        model.compile(\n",
        "            keras.optimizers.Adam(learning_rate=learning_rate), loss=\"categorical_crossentropy\", metrics=[\"accuracy\"],\n",
        "        )\n",
        "        return model\n",
        "\n",
        "    def fit(self, hp, model, *args, **kwargs):\n",
        "        return model.fit(\n",
        "            *args,\n",
        "            batch_size=hp.Choice(\"batch_size\", [256]),\n",
        "            **kwargs,\n",
        "        )\n",
        "\n",
        "tuner = kt.RandomSearch(\n",
        "    MyHyperModel(),\n",
        "    objective=\"val_accuracy\",\n",
        "    max_trials=50,\n",
        "    overwrite=True,\n",
        "    directory=\"my_dir\",\n",
        "    project_name=\"tune_hypermodel\",\n",
        ")"
      ],
      "metadata": {
        "id": "lBwTvP7R3Dv4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tuner.search_space_summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "npPJmu8y0c6n",
        "outputId": "1c7b298c-4a1e-4fab-9701-b512d551ea99"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Search space summary\n",
            "Default search space size: 4\n",
            "layers (Int)\n",
            "{'default': None, 'conditions': [], 'min_value': 1, 'max_value': 5, 'step': 1, 'sampling': None}\n",
            "units_0 (Int)\n",
            "{'default': None, 'conditions': [], 'min_value': 32, 'max_value': 512, 'step': 32, 'sampling': None}\n",
            "act_0 (Choice)\n",
            "{'default': 'relu', 'conditions': [], 'values': ['relu', 'tanh'], 'ordered': False}\n",
            "lr (Choice)\n",
            "{'default': 0.0001, 'conditions': [], 'values': [0.0001, 0.001, 0.01, 0.1], 'ordered': True}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Parameter tuning of multiple hidden layers"
      ],
      "metadata": {
        "id": "0LIvazFtruS3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tuner.search(X_train, Y_train, epochs=20, validation_data=(X_val, Y_val))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZG-8ukdp0QaO",
        "outputId": "1f39ccee-2b31-46e0-c5eb-5b59a4003ca6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 27 Complete [00h 06m 44s]\n",
            "val_accuracy: 0.25920000672340393\n",
            "\n",
            "Best val_accuracy So Far: 0.30079999566078186\n",
            "Total elapsed time: 04h 46m 50s\n",
            "\n",
            "Search: Running Trial #28\n",
            "\n",
            "Value             |Best Value So Far |Hyperparameter\n",
            "2                 |2                 |layers\n",
            "352               |384               |units_0\n",
            "tanh              |tanh              |act_0\n",
            "0.001             |0.001             |lr\n",
            "256               |256               |batch_size\n",
            "352               |416               |units_1\n",
            "relu              |relu              |act_1\n",
            "416               |448               |units_2\n",
            "tanh              |tanh              |act_2\n",
            "320               |None              |units_3\n",
            "relu              |None              |act_3\n",
            "160               |None              |units_4\n",
            "tanh              |None              |act_4\n",
            "\n",
            "Epoch 1/20\n",
            "1792/1792 [==============================] - 33s 18ms/step - loss: 3.2326 - accuracy: 0.2083 - val_loss: 2.9960 - val_accuracy: 0.2448\n",
            "Epoch 2/20\n",
            "1792/1792 [==============================] - 33s 18ms/step - loss: 3.0062 - accuracy: 0.2445 - val_loss: 2.9154 - val_accuracy: 0.2577\n",
            "Epoch 3/20\n",
            "1792/1792 [==============================] - 33s 18ms/step - loss: 2.9423 - accuracy: 0.2554 - val_loss: 2.8630 - val_accuracy: 0.2673\n",
            "Epoch 4/20\n",
            "1792/1792 [==============================] - 33s 18ms/step - loss: 2.9062 - accuracy: 0.2623 - val_loss: 2.8388 - val_accuracy: 0.2752\n",
            "Epoch 5/20\n",
            "1792/1792 [==============================] - 33s 19ms/step - loss: 2.8791 - accuracy: 0.2669 - val_loss: 2.8179 - val_accuracy: 0.2769\n",
            "Epoch 6/20\n",
            "1792/1792 [==============================] - 33s 18ms/step - loss: 2.8603 - accuracy: 0.2711 - val_loss: 2.7994 - val_accuracy: 0.2864\n",
            "Epoch 7/20\n",
            "1792/1792 [==============================] - 33s 18ms/step - loss: 2.8444 - accuracy: 0.2742 - val_loss: 2.7971 - val_accuracy: 0.2833\n",
            "Epoch 8/20\n",
            "1792/1792 [==============================] - 33s 18ms/step - loss: 2.8329 - accuracy: 0.2765 - val_loss: 2.7702 - val_accuracy: 0.2856\n",
            "Epoch 9/20\n",
            "1792/1792 [==============================] - 34s 19ms/step - loss: 2.8213 - accuracy: 0.2782 - val_loss: 2.7660 - val_accuracy: 0.2906\n",
            "Epoch 10/20\n",
            "1792/1792 [==============================] - 34s 19ms/step - loss: 2.8116 - accuracy: 0.2807 - val_loss: 2.7549 - val_accuracy: 0.2898\n",
            "Epoch 11/20\n",
            "1471/1792 [=======================>......] - ETA: 5s - loss: 2.8024 - accuracy: 0.2815"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Our randomized search in space of parameters shows us that the peak accuracy is 30 percent when we use two hidden layers with 300+ nodes and different activation functions"
      ],
      "metadata": {
        "id": "O7s_QN1pr0tQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I also tried the task with MLP classifier from Sklearn but the loss was greater than manually adding layers to a MLP"
      ],
      "metadata": {
        "id": "oPzjje7_rhU8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.neural_network import MLPClassifier\n",
        "\n",
        "# Create model object\n",
        "clf = MLPClassifier(hidden_layer_sizes=(3,128),\n",
        "                    random_state=42,\n",
        "                    solver='adam',\n",
        "                    batch_size=200,\n",
        "                    verbose=True,\n",
        "                    activation='relu',\n",
        "                    learning_rate_init=0.001)\n",
        "\n",
        "# Fit data onto the model\n",
        "clf.fit(X_train,Y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "103U6v3tCC2z",
        "outputId": "b139b2bc-c876-47f0-a1ca-b8e8e35afcd0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration 1, loss = 6.40504900\n",
            "Iteration 2, loss = 4.62790324\n",
            "Iteration 3, loss = 4.50327608\n",
            "Iteration 4, loss = 4.44926606\n",
            "Iteration 5, loss = 4.40704275\n",
            "Iteration 6, loss = 4.35908356\n",
            "Iteration 7, loss = 4.32303185\n",
            "Iteration 8, loss = 4.30264529\n",
            "Iteration 9, loss = 4.29081092\n",
            "Iteration 10, loss = 4.28227626\n",
            "Iteration 11, loss = 4.27655414\n",
            "Iteration 12, loss = 4.27272661\n",
            "Iteration 13, loss = 4.26862740\n",
            "Iteration 14, loss = 4.26614793\n",
            "Iteration 15, loss = 4.26279083\n",
            "Iteration 16, loss = 4.26130793\n",
            "Iteration 17, loss = 4.25982259\n",
            "Iteration 18, loss = 4.25799825\n",
            "Iteration 19, loss = 4.25664262\n",
            "Iteration 20, loss = 4.25501096\n",
            "Iteration 21, loss = 4.25455361\n",
            "Iteration 22, loss = 4.25320188\n",
            "Iteration 23, loss = 4.25223059\n",
            "Iteration 24, loss = 4.25136046\n",
            "Iteration 25, loss = 4.25025176\n",
            "Iteration 26, loss = 4.25039735\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:699: UserWarning: Training interrupted by user.\n",
            "  warnings.warn(\"Training interrupted by user.\")\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MLPClassifier(batch_size=200, hidden_layer_sizes=(3, 128), random_state=42,\n",
              "              verbose=True)"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p_s_MlLmDBq3",
        "outputId": "54c69318-16df-441a-dff3-2e05146caa46"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[]"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    },
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}